---
layout: post
title: "Tuning Machine Learning models with GPopt's new version"
description: "Hyperparameter tuning with GPopt, based on Gaussian processes"
date: 2024-01-29
categories: [Python]
comments: true
---

<span>
  <a target="_blank" rel="noreferrer noopener" href="https://colab.research.google.com/github/Techtonique/GPopt/blob/main/GPopt/demo/thierrymoudiki_20240129_tuning_BCN_classifier.ipynb">
    <img style="width: inherit;" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
  </a>
</span>


A new version of Python package `GPopt` is available on [PyPI](https://pypi.org/project/gpopt/). `GPopt` is a package for stochastic optimization based on Gaussian process regressors (for now, the name `GP*` is 'unfortunate'). This type of optimization is particularly useful for tuning machine learning models' hyperparameters.

The main change in `GPopt`'s `v0.3.0` is: the user can now choose a different **surrogate model** (see [this excellent book](https://bayesoptbook.com/) for more details on the procedure). 

You'll find below a link to a notebook showcasing the use of `GPopt` for tuning [Boosted Configuration Networks](https://thierrymoudiki.github.io/blog/2022/10/05/python/explainableml/interpretation-and-PI-for-BCN) (BCN version 0.7.0).

![xxx]({{base}}/images/2024-01-29/2024-01-29-image1.png){:class="img-responsive"}        

<span>
  <a target="_blank" rel="noreferrer noopener" href="https://colab.research.google.com/github/Techtonique/GPopt/blob/main/GPopt/demo/thierrymoudiki_20240129_tuning_BCN_classifier.ipynb">
    <img style="width: inherit;" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
  </a>
</span>

