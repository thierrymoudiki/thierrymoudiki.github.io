---
layout: post
title: "Backpropagating quasi-randomized neural networks"
description: "Backpropagating quasi-randomized neuralnetworks in Python package "
date: 2025-06-23
categories: Python
comments: true
---


The `FiniteDiffRegressor` -- implemented in Python package `tisthemachinelearner` -- **blends a finite difference-based training algorithm for (quasi-)randomized artificial neural network models' weights with any supervised Machine Learning regression model**. 

More details about the implementation can be found in this technical note: 

[https://www.researchgate.net/publication/392923564_Backpropagating_quasi-randomized_neural_networks](https://www.researchgate.net/publication/392923564_Backpropagating_quasi-randomized_neural_networks)

On GitHub: 

[https://github.com/Techtonique/tisthemachinelearner](https://github.com/Techtonique/tisthemachinelearner)

And here is a link to the notebook containing examples of use of `FiniteDiffRegressor`: 

<a target="_blank" href="https://colab.research.google.com/github/Techtonique/tisthemachinelearner/blob/main/examples/2025_06_23_custom_nnetsauce_gradient_descent.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" style="max-width: 100%; height: auto; width: 120px;"/>
</a>

![image-title-here]({{base}}/images/2025-06-23/2025-06-23-image1.png){:class="img-responsive"}    
