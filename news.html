<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
    <title>Thierry Moudiki - Webpage</title>
    <meta name="description" content="Personal webpage of Thierry Moudiki.">
    <meta name="author" content="Thierry Moudiki">
    <meta name="keywords" content="Thierry, Thierry Moudiki, webpage, nnetsauce, crossval">

    <!-- <meta property="og:image" content="http://thierry.me/images/thierry.jpg"> -->
    <meta property="og:url" content="http://thierrymoudiki.github.io">
    
    <meta property="og:title" content="Thierry Moudiki">
    <meta property="og:type" content="profile">
    <meta property="og:description" content="Personal webpage of Thierry Moudiki.">
    
    <!-- Mobile Specific Metas
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="stylesheet" href="css/normalize.css">
    <link rel="stylesheet" href="css/skeleton.css">
    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" title="Tomorrow Night Blue" href="css/tomorrow-night-blue.css">

    <!-- Favicon
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <!-- <link rel="icon" type="image/png" href="images/Logo.png"> -->

    <!-- FONT
    –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

</head>

  <body>
  <div class="container-fluid">
    <div class="row content" padding-right="30px">
  	
      
<!-- Blog posts container -->

      <div class="container col-sm-9">                

          <h1>Packages news</h1> 

          <a href="index.html">Back to homepage</a>

          <hr>

        <div class="container" id="post5-pypi-nnetsauce">

          <h2>nnetsauce is now available on Pypi!</h2>
          <h5><span class="glyphicon glyphicon-time"></span> Jun 05, 2019. | <a href="#">Top</a></h5>
          
          <br>

          <p>
            Machine Learning and Deep Learning package <a href="https://github.com/thierrymoudiki/nnetsauce">nnetsauce</a> (introduced <a href="#post3-nnetsauce">here</a>) is now available on <a href="https://pypi.org/">Pypi</a> -- and I'm so proud of it ;). Which means, you can install it by using the command line: 

          <div class="common">
          <pre>
            <code class="bash">              
              pip install nnetsauce
            </code>
          </pre>
        </div>


            For more <b>examples of use of this package</b>, you can consult <a href="#post4-more-nnetsauce">this post</a>, or the <a href="https://github.com/thierrymoudiki/nnetsauce">package's Github</a> README. 

          </p>

        </div>

        <hr>

        <div class="container" id="post4-more-nnetsauce">

          <h2>More nnetsauce (with examples)</h2>
          <h5><span class="glyphicon glyphicon-time"></span> May 09, 2019. | <a href="#">Top</a></h5>
          
          <br>

          <p>
            As mentioned in a <a href="#post3-nnetsauce">previous</a> post, <a href="https://github.com/thierrymoudiki/nnetsauce">nnetsauce</a> is a Python package for Statistical/Machine learning and deep learning, based on combinations of <i>neural</i> networks layers. It could be used for solving regression, classification and multivariate time series forecasting problems. This post makes a more detailed introduction of <code>nnetsauce</code>, with a few examples based on classification and deep learning. 
          </p>

        
          <h3>Installing the package</h3>        
        
          <p> Currently, <code>nnetsauce</code> can be installed through <a href="https://github.com/thierrymoudiki/nnetsauce">Github</a> (but it will be available on PyPi in a few weeks). 
          </p>

          <p>
          Here is how: 
          </p>
        
            <div class="common">
              <pre>
                <code class="bash">
                  
                  git clone https://github.com/thierrymoudiki/nnetsauce.git
                  cd nnetsauce
                  python setup.py install

                </code>
              </pre>
            </div>
                
          <h3>Examples of use of <code>nnetsauce</code></h3>                       

        <p>
          Below, are two examples of use of <a href="https://github.com/thierrymoudiki/nnetsauce"><code>nnetsauce</code></a>. A <a href="#classifex">classification</a> example based on breast cancer data, and an illustrative <a href="#deeplearningex">deep learning</a> example. In the classification example, we show how a logistic regression model can be enhanced, for a higher accuracy (accuracy is used here for simplicity), by using <code>nnetsauce</code>. The deep learning example shows how custom building blocks of <code>nnetsauce</code> objects can be combined together, to form a - perfectible - deeper learning architecture. 
        </p>
        
        <p>
          <code>scikit-learn</code> models are heavily used in these examples, but <code>nnetsauce</code> <b>will work with any learning model possessing methods <code>fit()</code> and <code>predict()</code></b> (plus, <code>predict_proba()</code> for a classifier). That is, it could be used in conjunction with <a href="https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_examples.py">xgboost</a>, <a href="https://github.com/Microsoft/LightGBM/blob/master/examples/python-guide/sklearn_example.py">LightGBM</a> or <a href="https://github.com/catboost">CatBoost</a> for example. For the purpose of <b>model validation</b>, <code>sklearn</code>'s  cross-validation functions such as <code>GridSearchCV</code> and <code>cross_val_score</code> can be employed (on <code>nnetsauce</code> models), as it will be shown in the classification example.
        </p> 

        <br>

        <h4 id="classifex">classification example</h3>
        
        <p>For this first example, we start by <b>fitting a logistic regression model to breast cancer data</b> on a training set, and measure its accuracy on a validation set: </p>

        <div class="common">
        <pre>
          <code class="python">
            
            # 0 - Packages ----- 

            # Importing the packages that will be used in the demo
            import nnetsauce as ns
            from sklearn import datasets, linear_model
            from sklearn.model_selection import train_test_split
            

            # 1 - Datasets -----

            # Loading breast cancer data
            breast_cancer = datasets.load_breast_cancer()
            Z = breast_cancer.data
            t = breast_cancer.target

            
            # 2 - Data splitting -----            

            # Separating the data into training/testing set, and 
            # a validation set
            Z_train, Z_test, t_train, t_test = train_test_split(
                Z, t, test_size=0.2, random_state=42)


            # 3 - Logistic regression -----

            # Fitting the Logistic regression model on 
            # training set
            regr = linear_model.LogisticRegression()                        
            regr.fit(Z_train, t_train)

            # predictive accuracy of the model on test set
            regr.score(Z_test, t_test)  

          </code>
          </pre>
        </div>

      <p>The accuracy of this model is equal to <code>0.9561</code>. The <b>logistic regression is now augmented of <code>n_hidden_features</code> additional features</b> with <code>nnetsauce</code>. We use <code>GridSearchCV</code> to find a better combination of hyperparameters;  additional hyperparameters such as row subsampling (<code>row_sample</code>) and <code>dropout</code> are included and reseached:</p>. 

      <div class="common">
        <pre>
          <code class="python">
            # Defining nnetsauce model
            # based on the logistic regression model
            # defined previously
            fit_obj = ns.CustomClassifier(
            obj=regr,
            n_hidden_features=10,
            direct_link=True,
            bias=True,
            nodes_sim="sobol",
            activation_name="relu", 
            seed = 123)
            
            # Grid search ---
            from sklearn.model_selection import GridSearchCV
            # grid search for finding better hyperparameters
            np.random.seed(123)
            clf = GridSearchCV(cv = 3, estimator = fit_obj,
                               param_grid={'n_hidden_features': range(5, 25), 
                                           'row_sample': [0.7,0.8, 0.9], 
                                           'dropout': [0.7, 0.8, 0.9], 
                                           'n_clusters': [0, 2, 3, 4]}, 
                                           verbose=2)
            
            # fitting the model
            clf.fit(Z_train, t_train)

            # 'best' hyperparameters found 
            print(clf.best_params_)
            print(clf.best_score_)

            # predictive accuracy on test set
            clf.best_estimator_.score(Z_test, t_test)

          </code>
          </pre>
        </div>

      <p>After using <code>nnetsauce</code>, the accuracy is now equal to <code>0.9692</code>.</p>

      <h4 id="deeplearningex">deep learning example</h3>

      <p>
        This second example, is an <b>illustrative</b> example of deep learning with <a href="https://github.com/thierrymoudiki/nnetsauce"><code>nnetsauce</code></a>. Many, <b>more advanced things could be tried</b>. In this example, predictive accuracy of the model <b>increases as new layers are added</b> to the stack. 
      </p>

      <p>
        The <b>first layer</b> is a Bayesian ridge regression. Model accuracy (Root Mean Squared Error, RMSE) is equal to <code>63.56</code>. The <b>second layer</b> notably uses 3 additional features, an hyperbolic tangent activation function and the first layer; accuracy is <code>61.76</code>. To finish, the <b>third layer</b> uses 5 additional features, a sigmoid activation function and the second layer. The final accuracy, after adding this third layer is equal to: <code>61.68</code>.
      </p>
        

      <div class="common">
        <pre>
          <code class="python">

            import nnetsauce as ns
            from sklearn import datasets, metrics

            diabetes = datasets.load_diabetes()
            X = diabetes.data 
            y = diabetes.target
            
            # layer 1 (base layer) ----
            layer1_regr = linear_model.BayesianRidge()
            layer1_regr.fit(X[0:100,:], y[0:100])
            # RMSE score
            np.sqrt(metrics.mean_squared_error(y[100:125], layer1_regr.predict(X[100:125,:])))


            # layer 2 using layer 1 ----
            layer2_regr = ns.CustomRegressor(obj = layer1_regr, n_hidden_features=3, 
                                    direct_link=True, bias=True, 
                                    nodes_sim='sobol', activation_name='tanh', 
                                    n_clusters=2)
            layer2_regr.fit(X[0:100,:], y[0:100])


            # RMSE score
            np.sqrt(layer2_regr.score(X[100:125,:], y[100:125]))

            # layer 3 using layer 2 ----
            layer3_regr = ns.CustomRegressor(obj = layer2_regr, n_hidden_features=5, 
                        direct_link=True, bias=True, 
                        nodes_sim='hammersley', activation_name='sigmoid', 
                        n_clusters=2)
            layer3_regr.fit(X[0:100,:], y[0:100])

            # RMSE score
            np.sqrt(layer3_regr.score(X[100:125,:], y[100:125]))

          </code>
          </pre>
        </div>

        <a href="#post4-more-nnetsauce">Back to the top of this blog</a>

        </div>

        <hr>

        <div class="container" id="post3-nnetsauce">

          <h2>nnetsauce</h2>
          <h5><span class="glyphicon glyphicon-time"></span> Mar 13, 2019. | <a href="#">Top</a></h5>
          
          <br>
          <p>

          <a href="https://github.com/thierrymoudiki/nnetsauce">nnetsauce</a> is a Python package for Statistical/Machine learning built on top of Numpy, Scipy, and scikit-learn under the BSD license. In nnetsauce, pattern recognition is achieved by combining single-layer networks (SLNN). These SLNN building blocks constitute the basis of many custom models that can be built by the user, including models with <b>deeper learning architectures</b>.
          
          <br>
          <br>

          <b>Examples of use, for illustration: </b> nnetsauce can for example be trained to distinguish between malignant or benign tumors, depending on their characteristics (see examples on <a href="https://github.com/thierrymoudiki/nnetsauce">Github</a>), <b>with a certain <u>degree of confidence</u></b> . Or, by using your historical data of income and expenditures, it can be trained to forecast your savings in the next months.  

          <br>
          <br>
          
          The package is very new. For those who want to try it, give feedback, make it available in R, contribute to the development on <a href="https://github.com/thierrymoudiki/nnetsauce">Github</a>, feel free to jump in.</p>
        
        </div>


        <hr>

        <div class="container" id="post2-crossval">

          <h2>crossval</h2>
          <h5><span class="glyphicon glyphicon-time"></span> Mar 13, 2019. | <a href="#">Top</a></h5>
          
          <br>
          <p>
            Statistical/Machine learning models often depend on many <i>hyperparameters</i>, that define and control their learning capabilities. <a href="https://github.com/thierrymoudiki/crossval">crossval</a> is an R package that calculates these models' learning performances on given datasets, as a function of their hyperparameters. 

            <br>
            <br>

            For those who want to contribute to the package development or improve it on <a href="https://github.com/thierrymoudiki/crossval">Github</a>, feel free to jump in.
          </p>
        
        </div>


        <hr>
        
        <div class="container" id="post1-loren-ipsum">

          <h2>loren ipsum blogging</h2>        
          <h5><span class="glyphicon glyphicon-time"></span> Sep 24, 2015. | <a href="#">Top</a></h5>

          <br>
          <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. 
          
          <br>
          <br>
          
          Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.</p>

        </div>


      <hr>

  <script src="static/js/highlight.pack.js"></script> 

  <script>hljs.initHighlightingOnLoad();</script> 

</body>
</html>
