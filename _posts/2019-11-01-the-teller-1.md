---
layout: post
title: "Introducing the teller"
description: the teller, a model-agnostic tool for Machine Learning explainability
date: 2019-11-01
---


There is an increasing need for __transparency__ and __fairness__ in Machine Learning (ML) models  predictions. Consider for example a banker who has to explain to a client why his/her loan application is rejected, or a health professional who must explain what constitutes his/her diagnosis. Some ML models are indeed very accurate, but are considered  hard to explain, relatively to popular linear models. 


__Source of figure__: James, Gareth, et al. An introduction to statistical learning. Vol. 112. New York: springer, 2013.
![Source: James, Gareth, et al. An introduction to statistical learning. Vol. 112. New York: springer, 2013.]({{base}}/images/2019-11-01/2019-11-01-image1.png){:class="img-responsive"}


We do not want to sacrifice this high accuracy to explainability.  Hence: __ML explainability__. There are a lot of ML explainability tools out there, _in the wild_ for that purpose (don't take my word for it).

The `teller` is a __model-agnostic tool for ML explainability__ - agnostic, as long as  this model possesses methods `fit` and `predict`. The `teller`'s philosophy is to rely on [Taylor series](https://en.wikipedia.org/wiki/Taylor_series) to explain ML models predictions: a little increase in model's explanatory variables + a little decrease, and we can obtain approximate sensitivities of its predictions to changes in these explanatory variables. 

## Installation 

Currently from Github, for the development version: 

```bash
pip install git+https://github.com/thierrymoudiki/teller.git
```

## Package description

This notebook will give you a good introduction:

[thierrymoudiki_011119_boston_housing.ipynb](https://github.com/thierrymoudiki/teller/blob/master/teller/demo/thierrymoudiki_011119_boston_housing.ipynb)

Two models are used in the notebook: a __linear model__ and a [Random Forest](https://en.wikipedia.org/wiki/Random_forest) (here, the _black-box_ model). The most straightforward way to illustrate the `teller` is to use a linear model. In this case, the effects of model covariates on the response can be directly related to the linear model's coefficients. Also, note that if there a lot of variables in your model, the `teller`'s explainer can be created with option `n_jobs=-1` (for parallel execution).


Contributions/remarks are welcome as usual, you can submit a pull request [on Github](https://github.com/thierrymoudiki/teller).


__Note:__ I am currently looking for a _gig_. You can hire me on [Malt](https://www.malt.fr/profile/thierrymoudiki) or send me an email: __thierry dot moudiki at pm dot me__. I can do descriptive statistics, data preparation, feature engineering, model calibration, training and validation, and model outputs' interpretation. I am fluent in Python, R, SQL, Microsoft Excel, Visual Basic (among others) and French. My résumé? [Here]({{base}}/cv/thierry-moudiki.pdf)!



