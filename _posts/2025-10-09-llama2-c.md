---
layout: post
title: "R port of llama2.c"
description: "R port of llama2.c (based on tiny stories)"
date: 2025-10-09
categories: R
comments: true
---

This is a post about the R port of llama2.c, a C implementation of a language model. The post includes installation instructions, code examples, and steps to run a Shiny app for experimenting with the model.

Code available at: [https://github.com/thierrymoudiki/llama2r/tree/main](https://github.com/thierrymoudiki/llama2r/tree/main)

# R port of llama2.c (https://github.com/karpathy/llama2.c)

Code and Shiny app for educational purpose. Experiment with temperature. 

![alt text](image.gif)

## Install 

```R
devtools::install_github("thierrymoudiki/llama2r")
```

Code example in [vignettes/getting-started.Rmd](vignettes/getting-started.Rmd). 

## Shiny app 

In [/vignettes/app.R](/vignettes/app.R)

## Reproducible steps 

### Step 1: Prepare the C Code

Clone the Repository:

```bash
git clone https://github.com/karpathy/llama2.c.git
cd llama2.c
```

### Step 2: Compile the C Code:

```bash
gcc -Ofast run.c -lm -o run
```

### Step 3: Download a Pretrained Model:

```bash
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories42M.bin
```

### Step 4: Download the Tokenizer:

```bash
wget https://huggingface.co/karpathy/tinyllamas/resolve/main/tokenizer.bin
```

### Step 5: Packaging

The `.bin`s are stored in `inst/bin`


### Step 6: Run the Shiny App

```R
library(shiny)
library(llama2r)
runApp(system.file("vignettes", "app.R", package = "llama2r"))
```
    
![image-title-here]({{base}}/images/2025-10-09/image.gif){:class="img-responsive"}
    